{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "Hm0OwTqL4-R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import gzip\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "yUo-3OG-4-VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_zipped_pickle(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        loaded_object = pickle.load(f)\n",
        "        return loaded_object\n",
        "\n",
        "BASEDIR = '/content/' # path to the preprocess_out files\n",
        "limit = None # limit how many files you want to load. For testing, probably start with <5\n",
        "files = [file for file in os.listdir(BASEDIR) if file.startswith('pp5doc')]  # list of all the files\n",
        "\n",
        "# load docs\n",
        "docs = []  # we'll load and append files into this. \n",
        "for file in files[:limit]:\n",
        "    print(file)\n",
        "    data = load_zipped_pickle(BASEDIR + file)\n",
        "    [docs.append(doc) for doc in data]   # each file is a list of docs, so we will flatten them here."
      ],
      "metadata": {
        "id": "fjNS3Kdd4-YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "6WqCIVVk4-bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]['tokens']"
      ],
      "metadata": {
        "id": "gTWp4Mog4-ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_sent = []\n",
        "for doc in docs:\n",
        "  token_sent.append(\" \".join(doc['tokens']))"
      ],
      "metadata": {
        "id": "ywFK-IyC4Z9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(token_sent))"
      ],
      "metadata": {
        "id": "aGtTfemb4bc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_sent[0]"
      ],
      "metadata": {
        "id": "akXZU49Q4bgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "cpJ3d2hj4bjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encode the sentences \n",
        "embeddings = model.encode(token_sent, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "zc0YPM9k4bmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "id": "mLnK6-M74brX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(embeddings)"
      ],
      "metadata": {
        "id": "X1KH7ZVt4btd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0]"
      ],
      "metadata": {
        "id": "OsK3LWBo4bv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0].shape"
      ],
      "metadata": {
        "id": "iLKjDGbX4by0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the similarity scores\n",
        "cosine_scores = util.cos_sim(embeddings, embeddings)"
      ],
      "metadata": {
        "id": "ch0LHBIx4b2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cosine_scores)\n",
        "\n",
        "type(cosine_scores)"
      ],
      "metadata": {
        "id": "Fy2neWsK4b56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute/find the highest similarity scores\n",
        "pairs = []\n",
        "for i in range(len(cosine_scores)-1):\n",
        "    for j in range(i+1, len(cosine_scores)):\n",
        "        pairs.append({'index': [i, j], 'score': cosine_scores[i] \n",
        "                                                             [j]})\n",
        "        \n",
        "#sort the scores in decreasing order \n",
        "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
        "for pair in pairs[0:10]:\n",
        "    i, j = pair['index']\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(token_sent[i],\n",
        "                                  token_sent[j], pair['score']))"
      ],
      "metadata": {
        "id": "ugaEU_k54aBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs[0]"
      ],
      "metadata": {
        "id": "_gW2-yPx4Y1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_sent[944]"
      ],
      "metadata": {
        "id": "s5XSRdGc4kpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_sent[1068]"
      ],
      "metadata": {
        "id": "eVIaDqqz4kzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}